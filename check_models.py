#!/usr/bin/env python3
"""
IndexTTS æ¨¡å‹æ–‡ä»¶æ£€æŸ¥è„šæœ¬
"""

import os
import yaml
from pathlib import Path

def check_model_files():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("IndexTTS æ¨¡å‹æ–‡ä»¶æ£€æŸ¥")
    print("=" * 50)
    
    checkpoints_dir = Path("checkpoints")
    if not checkpoints_dir.exists():
        print("âŒ checkpoints ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = checkpoints_dir / "config.yaml"
    if not config_path.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: checkpoints/config.yaml")
        return False
    
    print("âœ… é…ç½®æ–‡ä»¶å­˜åœ¨")
    
    # è¯»å–é…ç½®æ–‡ä»¶
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ")
        print(f"   ç‰ˆæœ¬: {config.get('version', 'unknown')}")
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = {
        "GPTæ¨¡å‹": config.get('gpt_checkpoint', 'gpt.pth'),
        "BigVGANæ¨¡å‹": config.get('bigvgan_checkpoint', 'bigvgan_generator.pth'),
        "DVAEæ¨¡å‹": config.get('dvae_checkpoint', 'dvae.pth'),
        "BPEæ¨¡å‹": "bpe.model"
    }
    
    all_files_exist = True
    total_size = 0
    
    for model_name, filename in model_files.items():
        file_path = checkpoints_dir / filename
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            total_size += size_mb
            print(f"âœ… {model_name}: {filename} ({size_mb:.1f}MB)")
        else:
            print(f"âŒ {model_name}: {filename} (æ–‡ä»¶ä¸å­˜åœ¨)")
            all_files_exist = False
    
    print(f"\nğŸ“Š æ¨¡å‹æ–‡ä»¶æ€»å¤§å°: {total_size:.1f}MB")
    
    # æ£€æŸ¥å…¶ä»–æ–‡ä»¶
    other_files = [
        "unigram_12000.vocab",
        "bigvgan_discriminator.pth"
    ]
    
    print("\nå…¶ä»–æ–‡ä»¶æ£€æŸ¥:")
    for filename in other_files:
        file_path = checkpoints_dir / filename
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"âœ… {filename} ({size_mb:.1f}MB)")
        else:
            print(f"âš ï¸  {filename} (å¯é€‰æ–‡ä»¶)")
    
    if all_files_exist:
        print("\nğŸ‰ æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶éƒ½å­˜åœ¨ï¼")
        return True
    else:
        print("\nâŒ ç¼ºå°‘å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶")
        return False

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("\nä¾èµ–æ£€æŸ¥:")
    print("-" * 30)
    
    required_packages = [
        'torch',
        'torchaudio',
        'fastapi',
        'uvicorn',
        'pydantic',
        'omegaconf',
        'yaml'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package}")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements_api.txt")
        return False
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–åŒ…éƒ½å·²å®‰è£…")
    return True

def check_gpu():
    """æ£€æŸ¥GPU"""
    print("\nGPUæ£€æŸ¥:")
    print("-" * 30)
    
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ… CUDAå¯ç”¨: {gpu_name} (å…± {gpu_count} ä¸ªGPU)")
            
            # æ£€æŸ¥CUDAç‰ˆæœ¬
            cuda_version = torch.version.cuda
            print(f"   CUDAç‰ˆæœ¬: {cuda_version}")
            
            # æ£€æŸ¥PyTorchç‰ˆæœ¬
            pytorch_version = torch.__version__
            print(f"   PyTorchç‰ˆæœ¬: {pytorch_version}")
            
            return True
        elif hasattr(torch, "mps") and torch.backends.mps.is_available():
            print("âœ… MPS (Apple Silicon) å¯ç”¨")
            return True
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            return False
    except Exception as e:
        print(f"âŒ GPUæ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("IndexTTS ç¯å¢ƒæ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    models_ok = check_model_files()
    
    # æ£€æŸ¥ä¾èµ–
    deps_ok = check_dependencies()
    
    # æ£€æŸ¥GPU
    gpu_ok = check_gpu()
    
    print("\n" + "=" * 50)
    print("æ£€æŸ¥ç»“æœæ€»ç»“:")
    print(f"æ¨¡å‹æ–‡ä»¶: {'âœ… æ­£å¸¸' if models_ok else 'âŒ å¼‚å¸¸'}")
    print(f"ä¾èµ–åŒ…: {'âœ… æ­£å¸¸' if deps_ok else 'âŒ å¼‚å¸¸'}")
    print(f"GPUç¯å¢ƒ: {'âœ… æ­£å¸¸' if gpu_ok else 'âš ï¸  CPUæ¨¡å¼'}")
    
    if models_ok and deps_ok:
        print("\nğŸ‰ ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¯åŠ¨APIæœåŠ¡")
        print("è¿è¡Œå‘½ä»¤: python start_api.py")
    else:
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")

if __name__ == "__main__":
    main() 